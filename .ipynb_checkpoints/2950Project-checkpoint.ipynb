{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Decription \n",
    "\n",
    "Our raw dataset contains information about 200 trending videos on YouTube across 205 days. This data was collected from Canada, United States, Great Britain, Germany, France, Russia, Mexico, South Korea, Japan, and India. It includes the video id, the date(s) the video was trending, the video title, the channel name, the number of likes, dislikes, and views at that trending date, the category ID corresponding to the relevant genre of the video, the comment count, the time the video was published, all its tags it was posted under, a link to the thumbnail image used for the video, a boolean values for whether or not the video ever had its comments disabled, ratings disabled, or had an error/was removed, a direct copy and paste of each video’s description, and the link ID to the video. Youtube determines if a video is trending by looking at various factors including number of views, shares, comments, and likes. This dataset was created to explore which videos are trending in certain countries and why, in regards to its raw data, perhaps to better understand how exactly a posted video goes viral and stays viral, and why it garners such attention. “Mitchell J”, a kaggle user, funded the creation of this dataset, and says in the description it was collected using YouTube’s own API’s to gather the relevant raw data. In that regard, since YouTube’s own API was used to scrape this data, only readily-available surface data on the video is included here. Essentially any statistic on a video that you can see when you watch a video is what is included here. \n",
    "\n",
    "In terms of pre-processing the data, we had to combine the files for all of the countries we decided to use into one data file. We decided to use only countries that had mostly characters that could be interpreted on the computer. These countries included Canada, Germany, France, Great Britain, and the United States. We decided to just look at the videos under the music category because Youtube is largely used for music. After loading all of the csv files and json files for each country, we determined the category number for music by looking at the json. We then filtered out any videos in each of the Canada, Germany, France, Great Britain, and the United States datasets that were not of the “Music” category. There were many repeats of trending videos on certain days across countries, so we added a column to the dataset that contained a list of countries that a particular video was trending in on a particular day. This allowed for us to just be able to append all of the datasets together and drop the duplicates to give us unique rows, but still distinguish which videos were trending when and in what countries. Additionally we dropped the columns with the link for the thumbnail image of the video, the category id, since they were all the same, and for the description of the video because we felt we would not use it in our analysis.\n",
    "\n",
    "After this initial filtering, we still noticed some issues. Many videos had titles that were written in languages that did not port well into alpha-numeric characters, and showed up as glitchy unicode when looking at the raw data. In order to cut down on this, we filtered down each video that was essentially unusable due to its title/tags data. Each corresponding video per tag that did not contain only alphanumeric characters was flagged and removed from the csv. We also noticed many issues with the dating format of the videos. Each video had a corresponding column for the day it was trending, and the date it was published. The trending_day column was formatted oddly, in year/day/month, and the publish_date was a combined date/time string, so we formatted them all to be consistent. The publish_date was split into 2 columns, one representing the day, and one representing the exact time the video was uploaded. The trending_date column was formatted to the more standard month/day/year format, as was the published_day column. The publish_time column was left in 24 hour format to eliminate any issues with AM/PM. \n",
    "\n",
    "We combined multiple individual csv files, that were over 50 MB each, and json files into one csv file that is about 4 MB. After processing the raw data to combine multiple files into one cohesive dataset, our final dataset that we will use for this project contains trending videos, under the music category, over 205 days in Canada, Germany, France, Great Britain, and the United States. The attributes it contains are the video ids, the date the video was trending, the title of the video, the title of the channel of the video, the time the video was published, the date the video was published, the tags, the number of view, number of likes, number of dislikes, number of comments, and a list of the countries that a video was trending in on a particular day. \n",
    "\n",
    "\n",
    "Link to raw data: https://drive.google.com/drive/folders/1MEz1kqZ3AQVY_bdPxITEpsYqLlYEUBU-?usp=sharing\n",
    "\n",
    "### Potential Problems\n",
    "* Any non-English characters do not show up correctly when loading data, so we will focus on Canada, Germany, France, Great Britain, and the United States. Even when limiting to these countries, the dataset is much larger than 20 MB, so we will have to filter it to trim down the size. \n",
    "* In terms of sheer volume, there is a lot of data collected. 16 unique points per video for 200 videos a day across every day for 6 months adds up to a lot of raw data that must be filtered down into what is relevant to our work. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Dataset\n",
    "df = pd.read_csv(\"filtered_US_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
